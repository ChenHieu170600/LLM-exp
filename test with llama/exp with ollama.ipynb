{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the limitation of this model (llama3.2) running ollama server, what is ollama any whay?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama (Open-Source Large Language Model Application) and Ollama Server are not well-known entities in the field of natural language processing or AI. However, I found a possible connection to the LLaMA model.\n",
      "\n",
      "Llama is an open-source large language model developed by Meta AI. It was released as version 3.2, which you mentioned.\n",
      "\n",
      "The limitations of the LLaMA model (version 3.2) running on Ollama Server are not explicitly stated, but here are some general limitations of the LLaMA model:\n",
      "\n",
      "1. **Computational resources**: Large language models like LLaMA require significant computational power to train and run efficiently.\n",
      "2. **Memory requirements**: The model's massive size (over 175 billion parameters) means it requires substantial memory to store and process during inference.\n",
      "3. **Training data limitations**: While the model has been trained on a massive dataset, its performance can be limited by the quality and quantity of this data.\n",
      "4. **Contextual understanding**: Large language models like LLaMA struggle with contextual understanding and common sense, often relying on heuristics to fill in gaps.\n",
      "\n",
      "Ollama Server might refer to an open-source implementation or wrapper around the LLaMA model, allowing users to deploy the model on their servers for various applications. However, without more information about Ollama Server, I couldn't provide specific details on its limitations.\n",
      "\n",
      "If you have any further questions or would like to know more about LLaMA or other large language models, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can save time and resources for content creators and improve consistency.\n",
      "2. **Image and Video Editing**: Generative AI can create new images or edit existing ones to enhance visual content, reduce editing time, and increase productivity.\n",
      "3. **Chatbots and Virtual Assistants**: AI-powered chatbots can provide 24/7 customer support, answer frequently asked questions, and route complex queries to human agents.\n",
      "4. **Product Design**: Generative AI can create new product designs, prototypes, or even entire product lines, reducing design time and costs.\n",
      "5. **Music and Audio Generation**: AI can generate music, sound effects, and audio tracks for various applications such as video games, advertisements, and more.\n",
      "6. **Predictive Maintenance**: Generative AI can analyze sensor data to predict equipment failures, reducing downtime and increasing overall efficiency.\n",
      "7. **Personalized Recommendations**: AI-powered systems can analyze customer behavior and preferences to provide personalized product recommendations.\n",
      "8. **Language Translation**: Generative AI can translate text, speech, or entire conversations in real-time, breaking language barriers.\n",
      "9. **Marketing and Advertising**: AI can generate targeted ads, create personalized marketing campaigns, and optimize ad performance.\n",
      "10. **Autonomous Systems**: Generative AI can enable autonomous vehicles, drones, and robots to make decisions and adapt to new situations.\n",
      "\n",
      "Some specific industries that are already leveraging generative AI include:\n",
      "\n",
      "1. **Finance**: Generative AI is being used for risk assessment, portfolio management, and credit scoring.\n",
      "2. **Healthcare**: AI-powered systems can analyze medical images, generate prescriptions, and develop personalized treatment plans.\n",
      "3. **Education**: Generative AI can create customized learning materials, assess student performance, and provide feedback.\n",
      "4. **Manufacturing**: Generative AI is being used for predictive maintenance, quality control, and process optimization.\n",
      "5. **Media and Entertainment**: AI-powered tools are being used to generate music, sound effects, and special effects in films and video games.\n",
      "\n",
      "These applications are just a few examples of the many ways generative AI can transform businesses and industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can provide some general information about the OLLAMA model and its limitations.\n",
      "\n",
      "OLLAMA (Ollie's Large Language Application Model Algorithm) is a large language model developed by Meta AI, similar to other models like BERT-DNA-Max and Pegasus. \n",
      "\n",
      "OLLAMA is not publicly available yet for direct use via a web interface, but some experiments using the model have been mentioned recently.\n",
      "\n",
      "One of the limitations of this OLLAMA (llama3.2) server could be that the results may vary depending upon the specific set of words used as prompts, although it should theoretically output the same response to two different inputs.\n",
      "\n",
      "Limitations: \n",
      "1. Out of Domain  : The model may not perform well on tasks that are outside of its domain i.e. tasks which do not fall in our predefined list so there might be some error.\n",
      "2. Context Window Limitation-: For any given context window input, the maximum length for an answer will depend on this size constraint and should ideally be less than 2048.\n",
      "\n",
      "If you have any additional information about OLLAMA3.2 server limitations then let me know\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
